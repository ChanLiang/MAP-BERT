2020-02-24 05:09:05 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, add_prev_output_tokens=False, all_gather_list_size=16384, arch='roberta_leaner', attention_dropout=0.1, best_checkpoint_metric='accuracy', bpe=None, broadcast_buffers=False, bucket_cap_mb=25, classification_head_name='sentence_classification_head', clip_norm=0.0, cpu=False, criterion='sentence_prediction', curriculum=0, data='/home/tianyuan/data/glue-32768-fast/QNLI-bin/', dataset_impl=None, ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, end_learning_rate=0.0, fast_stat_sync=False, find_unused_parameters=True, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, log_format=None, log_interval=1000, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=10, max_positions=512, max_sentences=32, max_sentences_valid=32, max_tokens=4400, max_tokens_valid=4400, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_shuffle=False, num_classes=2, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, regression_target=False, required_batch_size_multiple=1, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='/home/tianyuan/exps/fairseq/Robera-base-masker-32768-p512-b256-c0.3/checkpoint_7_200000.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, seed=249347826, sentence_avg=False, separator_token=2, skip_invalid_size_inputs_valid_test=False, task='sentence_prediction', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, total_num_update=33112, train_subset='train', truncate_sequence=False, update_freq=[1], use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_updates=1986, weight_decay=0.1)
2020-02-24 05:09:05 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 32769 types
2020-02-24 05:09:05 | INFO | fairseq.tasks.sentence_prediction | [label] dictionary: 9 types
2020-02-24 05:09:05 | INFO | fairseq.data.data_utils | loaded 5463 examples from: /home/tianyuan/data/glue-32768-fast/QNLI-bin/input0/valid
2020-02-24 05:09:05 | INFO | fairseq.data.data_utils | loaded 5463 examples from: /home/tianyuan/data/glue-32768-fast/QNLI-bin/input1/valid
2020-02-24 05:09:05 | INFO | fairseq.data.data_utils | loaded 5463 examples from: /home/tianyuan/data/glue-32768-fast/QNLI-bin/label/valid
2020-02-24 05:09:05 | INFO | fairseq.tasks.sentence_prediction | Loaded valid with #samples: 5463
2020-02-24 05:09:09 | INFO | fairseq_cli.train | RobertaMaskLeaner(
  (decoder): RobertaEncoder(
    (sentence_encoder): TransformerSentenceEncoder(
      (embed_tokens): Embedding(32769, 768, padding_idx=1)
      (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)
      (layers): ModuleList(
        (0): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (3): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (4): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (5): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (6): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (7): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (8): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (9): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (10): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (11): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (emb_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): RobertaLMHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
  )
  (masker): MaskerEncoder(
    (sentence_encoder): TransformerSentenceEncoder(
      (embed_tokens): Embedding(32769, 768, padding_idx=1)
      (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)
      (layers): ModuleList(
        (0): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (1): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (2): TransformerSentenceEncoderLayer(
          (self_attn): MultiheadAttention(
            (k_proj): Linear(in_features=768, out_features=768, bias=True)
            (v_proj): Linear(in_features=768, out_features=768, bias=True)
            (q_proj): Linear(in_features=768, out_features=768, bias=True)
            (out_proj): Linear(in_features=768, out_features=768, bias=True)
          )
          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (fc1): Linear(in_features=768, out_features=3072, bias=True)
          (fc2): Linear(in_features=3072, out_features=768, bias=True)
          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
      )
      (emb_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (lm_head): RobertaMaskLeanerHead(
      (dense): Linear(in_features=768, out_features=1, bias=True)
    )
  )
  (classification_heads): ModuleDict(
    (sentence_classification_head): RobertaClassificationHead(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
      (out_proj): Linear(in_features=768, out_features=2, bias=True)
    )
  )
)
2020-02-24 05:09:09 | INFO | fairseq_cli.train | model roberta_leaner, criterion SentencePredictionCriterion
2020-02-24 05:09:09 | INFO | fairseq_cli.train | num. model params: 158661636 (num. trained: 158661636)
2020-02-24 05:09:12 | INFO | fairseq_cli.train | training on 1 GPUs
2020-02-24 05:09:12 | INFO | fairseq_cli.train | max tokens per GPU = 4400 and max sentences per GPU = 32
2020-02-24 05:09:12 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.dense.weight
2020-02-24 05:09:12 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.dense.bias
2020-02-24 05:09:12 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.out_proj.weight
2020-02-24 05:09:12 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.out_proj.bias
2020-02-24 05:09:13 | INFO | fairseq.trainer | loaded checkpoint /home/tianyuan/exps/fairseq/Robera-base-masker-32768-p512-b256-c0.3/checkpoint_7_200000.pt (epoch 7 @ 0 updates)
2020-02-24 05:09:13 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16
2020-02-24 05:09:13 | INFO | fairseq.trainer | loading train data for epoch 0
2020-02-24 05:09:13 | INFO | fairseq.data.data_utils | loaded 104743 examples from: /home/tianyuan/data/glue-32768-fast/QNLI-bin/input0/train
2020-02-24 05:09:13 | INFO | fairseq.data.data_utils | loaded 104743 examples from: /home/tianyuan/data/glue-32768-fast/QNLI-bin/input1/train
2020-02-24 05:09:13 | INFO | fairseq.data.data_utils | loaded 104743 examples from: /home/tianyuan/data/glue-32768-fast/QNLI-bin/label/train
2020-02-24 05:09:13 | INFO | fairseq.tasks.sentence_prediction | Loaded train with #samples: 104743
2020-02-24 05:09:13 | WARNING | fairseq.data.data_utils | 5 samples have invalid sizes and will be skipped, max_positions=512, first few sample ids=[2711, 84277, 88427, 82398, 82549]
epoch 001 | loss 0.71 | nll_loss 0.014 | accuracy 74.9 | wps 7352.3 | ups 4.69 | wpb 1567.4 | bsz 31.6 | num_updates 3318 | lr 9.57206e-06 | gnorm 5.014 | clip 0 | oom 0 | train_wall 698 | ppl 1.01 | wall 709
epoch 001 | valid on 'valid' subset | loss 0.525 | nll_loss 0.01 | accuracy 84.5 | wps 25838.3 | wpb 1607.8 | bsz 31.6 | ppl 1.01 | num_updates 3318
2020-02-24 05:21:42 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint1.pt (epoch 1 @ 3318 updates, score 84.5) (writing took 30.290983041049913 seconds)
epoch 002 | loss 0.467 | nll_loss 0.009 | accuracy 86.5 | wps 6954.9 | ups 4.44 | wpb 1567.4 | bsz 31.6 | num_updates 6636 | lr 8.50607e-06 | gnorm 5.873 | clip 0 | oom 0 | train_wall 697 | ppl 1.01 | wall 1457
epoch 002 | valid on 'valid' subset | loss 0.388 | nll_loss 0.008 | accuracy 89.1 | wps 25810.2 | wpb 1607.8 | bsz 31.6 | ppl 1.01 | num_updates 6636 | best_accuracy 89.1
2020-02-24 05:34:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint2.pt (epoch 2 @ 6636 updates, score 89.1) (writing took 20.79954222193919 seconds)
epoch 003 | loss 0.34 | nll_loss 0.007 | accuracy 90.7 | wps 7023.6 | ups 4.48 | wpb 1567.4 | bsz 31.6 | num_updates 9954 | lr 7.44008e-06 | gnorm 6.476 | clip 0 | oom 0 | train_wall 699 | ppl 1 | wall 2197
epoch 003 | valid on 'valid' subset | loss 0.386 | nll_loss 0.008 | accuracy 89.8 | wps 25722.9 | wpb 1607.8 | bsz 31.6 | ppl 1.01 | num_updates 9954 | best_accuracy 89.8
2020-02-24 05:46:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint3.pt (epoch 3 @ 9954 updates, score 89.8) (writing took 13.88156717387028 seconds)
epoch 004 | loss 0.243 | nll_loss 0.005 | accuracy 93.7 | wps 7111.6 | ups 4.54 | wpb 1567.4 | bsz 31.6 | num_updates 13272 | lr 6.37409e-06 | gnorm 7.027 | clip 0 | oom 0 | train_wall 697 | ppl 1 | wall 2928
epoch 004 | valid on 'valid' subset | loss 0.413 | nll_loss 0.008 | accuracy 90 | wps 25821.1 | wpb 1607.8 | bsz 31.6 | ppl 1.01 | num_updates 13272 | best_accuracy 90
2020-02-24 05:58:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint4.pt (epoch 4 @ 13272 updates, score 90.0) (writing took 20.54764625802636 seconds)
epoch 005 | loss 0.171 | nll_loss 0.003 | accuracy 95.7 | wps 7049.7 | ups 4.5 | wpb 1567.4 | bsz 31.6 | num_updates 16590 | lr 5.3081e-06 | gnorm 7.363 | clip 0 | oom 0 | train_wall 697 | ppl 1 | wall 3666
epoch 005 | valid on 'valid' subset | loss 0.443 | nll_loss 0.009 | accuracy 90.3 | wps 25885.9 | wpb 1607.8 | bsz 31.6 | ppl 1.01 | num_updates 16590 | best_accuracy 90.3
2020-02-24 06:10:52 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint5.pt (epoch 5 @ 16590 updates, score 90.3) (writing took 23.387876675929874 seconds)
epoch 006 | loss 0.119 | nll_loss 0.002 | accuracy 97.1 | wps 7011.6 | ups 4.47 | wpb 1567.4 | bsz 31.6 | num_updates 19908 | lr 4.24211e-06 | gnorm 7.219 | clip 0 | oom 0 | train_wall 698 | ppl 1 | wall 4408
epoch 006 | valid on 'valid' subset | loss 0.548 | nll_loss 0.011 | accuracy 89.9 | wps 25775.8 | wpb 1607.8 | bsz 31.6 | ppl 1.01 | num_updates 19908 | best_accuracy 90.3
2020-02-24 06:23:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint6.pt (epoch 6 @ 19908 updates, score 89.9) (writing took 9.535368142882362 seconds)
epoch 007 | loss 0.087 | nll_loss 0.002 | accuracy 97.9 | wps 7134.6 | ups 4.55 | wpb 1567.4 | bsz 31.6 | num_updates 23226 | lr 3.17612e-06 | gnorm 6.824 | clip 0 | oom 0 | train_wall 699 | ppl 1 | wall 5137
epoch 007 | valid on 'valid' subset | loss 0.6 | nll_loss 0.012 | accuracy 89.7 | wps 25738 | wpb 1607.8 | bsz 31.6 | ppl 1.01 | num_updates 23226 | best_accuracy 90.3
2020-02-24 06:35:12 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint7.pt (epoch 7 @ 23226 updates, score 89.7) (writing took 12.623136625159532 seconds)
epoch 008 | loss 0.064 | nll_loss 0.001 | accuracy 98.5 | wps 7117.1 | ups 4.54 | wpb 1567.4 | bsz 31.6 | num_updates 26544 | lr 2.11013e-06 | gnorm 6.223 | clip 0 | oom 0 | train_wall 697 | ppl 1 | wall 5868
epoch 008 | valid on 'valid' subset | loss 0.628 | nll_loss 0.012 | accuracy 90 | wps 25786.1 | wpb 1607.8 | bsz 31.6 | ppl 1.01 | num_updates 26544 | best_accuracy 90.3
2020-02-24 06:47:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint8.pt (epoch 8 @ 26544 updates, score 90.0) (writing took 10.318801797926426 seconds)
epoch 009 | loss 0.049 | nll_loss 0.001 | accuracy 98.9 | wps 7135.2 | ups 4.55 | wpb 1567.4 | bsz 31.6 | num_updates 29862 | lr 1.04414e-06 | gnorm 5.663 | clip 0 | oom 0 | train_wall 698 | ppl 1 | wall 6596
epoch 009 | valid on 'valid' subset | loss 0.695 | nll_loss 0.014 | accuracy 90.2 | wps 25780.9 | wpb 1607.8 | bsz 31.6 | ppl 1.01 | num_updates 29862 | best_accuracy 90.3
2020-02-24 06:59:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint9.pt (epoch 9 @ 29862 updates, score 90.2) (writing took 11.45917500113137 seconds)
epoch 010 | loss 0.041 | nll_loss 0.001 | accuracy 99.1 | wps 7128.3 | ups 4.55 | wpb 1567.4 | bsz 31.6 | num_updates 33180 | lr 0 | gnorm 5.12 | clip 0 | oom 0 | train_wall 698 | ppl 1 | wall 7326
epoch 010 | valid on 'valid' subset | loss 0.703 | nll_loss 0.014 | accuracy 90.2 | wps 25761.7 | wpb 1607.8 | bsz 31.6 | ppl 1.01 | num_updates 33180 | best_accuracy 90.3
2020-02-24 07:11:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint10.pt (epoch 10 @ 33180 updates, score 90.2) (writing took 12.939839672064409 seconds)
2020-02-24 07:11:41 | INFO | fairseq_cli.train | done training in 7348.5 seconds
Random Seed: 249347826
 CUDA_VISIBLE_DEVICES=1 python3 train.py ~/data/glue-32768-fast/QNLI-bin/ --restore-file /home/tianyuan/exps/fairseq/Robera-base-masker-32768-p512-b256-c0.3/checkpoint_7_200000.pt --max-positions 512 --max-sentences 32 --max-tokens 4400 --task sentence_prediction --reset-optimizer --reset-dataloader --reset-meters --required-batch-size-multiple 1     --init-token 0 --separator-token 2 --arch roberta_leaner --criterion sentence_prediction --num-classes 2 --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.1     --optimizer adam --adam-betas '(0.9, 0.98)' --adam-eps 1e-06     --clip-norm 0.0 --lr-scheduler polynomial_decay --lr 1e-05 --total-num-update 33112 --warmup-updates 1986 --seed 249347826 --max-epoch 10     --find-unused-parameters     --best-checkpoint-metric accuracy --maximize-best-checkpoint-metric;
